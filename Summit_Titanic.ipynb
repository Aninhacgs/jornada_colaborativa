{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summit Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mrB5PkZmvE_g",
        "LEPZsIPuagiN",
        "LtEcgeU5TJ_P",
        "wsL-O6uXTNj3",
        "ho9M0tfIv2cI",
        "4hj1K8-lS-jC",
        "KXkucYKYc89J",
        "hFqQ4ea97rmg",
        "DVzUIVFC7uQ9",
        "hrNEmCHsUvud",
        "k0QQkF6sb6R6",
        "Ky0po2qlkWnv",
        "uLszGdCSB_eW",
        "pk4SNCw2BzjV",
        "gWcImuLjGvTg",
        "BeZ6gB0oB2P8",
        "O4vzAbA4CLqC",
        "17Q56gTwBQ7Z",
        "xiZorlxkGK-e",
        "Q6hTzFUdCUDX",
        "YUT33Y5dDxfJ",
        "eb-SZ1F-Cdqh",
        "6w0cBrnor9UH",
        "Ct-oW5_vhmev",
        "nMqxa1OAhxCb",
        "X02Wvv2IhiIb",
        "UQJuQb_8sk6J",
        "jl06Sl5wppnF",
        "SCziFJiUsO0f",
        "KeSzF7z0AE7M",
        "ngm7gf_AcS5d",
        "xBcE7ssUcYbC",
        "b3PwYx0Ycmc5",
        "p3_n3Ovj0M89",
        "QIl3zfY2ZmSa",
        "xlKBrl2IvQYo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiohfg/jornada_colaborativa/blob/master/Summit_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPZsIPuagiN",
        "colab_type": "text"
      },
      "source": [
        "# Problem definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtEcgeU5TJ_P",
        "colab_type": "text"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhI_zsl7anTJ",
        "colab_type": "text"
      },
      "source": [
        "<p><b>RMS Titanic</b> was a British passenger liner operated by the White Star Line that sank in the North Atlantic Ocean in the early morning hours of <b>15 April 1912</b>, after striking an iceberg during her maiden voyage from Southampton to New York City. Of the estimated <b>2,224</b> passengers and crew aboard, more than <b>1,500</b> died, making the sinking one of modern history's deadliest peacetime commercial marine disasters.</p>\n",
        "\n",
        "<p>After leaving <b>Southampton</b> on 10 April 1912, Titanic called at <b>Cherbourg</b> in France and <b>Queenstown</b> (now Cobh) in Ireland, before heading west to <b>New York</b>. On 14 April, four days into the crossing and about 375 miles (600 km) south of Newfoundland, she <b>hit an iceberg at 11:40 p.m. ship's time</b>. The collision caused the hull plates to buckle inwards along her starboard (right) side and opened five of her sixteen watertight compartments to the sea.</p>\n",
        "\n",
        "<p>Meanwhile, passengers and some crew members were evacuated in lifeboats, many of which were launched only partially loaded. A disproportionate number of men were left aboard because of a \"women and children first\" protocol for loading lifeboats. <b>At 2:20 a.m., she broke apart and foundered with well over one thousand people still aboard.</b> Just under two hours after Titanic sank, the Cunard liner RMS Carpathia arrived and brought aboard an estimated <b>705 survivors</b>.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsL-O6uXTNj3",
        "colab_type": "text"
      },
      "source": [
        "### The problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inmheZNhTP-E",
        "colab_type": "text"
      },
      "source": [
        "Binary classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho9M0tfIv2cI",
        "colab_type": "text"
      },
      "source": [
        "# Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29XmO9r2Tt-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removes all warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocWuq1pwzVq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWD5tVa1zAsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "import requests\n",
        "from scipy.special import factorial\n",
        "import seaborn as sns\n",
        "from termcolor import colored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br1DTA9Dl224",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn as sk\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hj1K8-lS-jC",
        "colab_type": "text"
      },
      "source": [
        "# Constants (URLs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHFEDUa3TBh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL_CSV = \"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv\"\n",
        "URL_DECKS = \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Titanic_side_plan_with_lifeboats.png/1280px-Titanic_side_plan_with_lifeboats.png\"\n",
        "URL_DISASTER = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/The_destruction_of_RMS_Titanic.jpg/1280px-The_destruction_of_RMS_Titanic.jpg\"\n",
        "URL_HTML = \"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/Ctitanic3.html\"\n",
        "URL_ICEBERG = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Iceberg_in_the_Arctic_with_its_underside_exposed.jpg/1280px-Iceberg_in_the_Arctic_with_its_underside_exposed.jpg\"\n",
        "URL_LIFEBOAT = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Titanic_lifeboat.jpg/1280px-Titanic_lifeboat.jpg\"\n",
        "URL_PASSENGERS = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Crowd_at_Pier_54_awaiting_Carpathia_arrival_1912.jpg/1280px-Crowd_at_Pier_54_awaiting_Carpathia_arrival_1912.jpg\"\n",
        "URL_PYTHON = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Pit%C3%B3n_de_la_India_%28Python_molurus%29%2C_Zoo_de_Ciudad_Ho_Chi_Minh%2C_Vietnam%2C_2013-08-14%2C_DD_08.JPG/1280px-Pit%C3%B3n_de_la_India_%28Python_molurus%29%2C_Zoo_de_Ciudad_Ho_Chi_Minh%2C_Vietnam%2C_2013-08-14%2C_DD_08.JPG\"\n",
        "URL_SHIPYARD = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/RMS_Titanic_ready_for_launch%2C_1911.jpg/1280px-RMS_Titanic_ready_for_launch%2C_1911.jpg\"\n",
        "URL_SURVIVORS = \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/19120417_Some_who_were_saved_when_the_Titanic_went_down_-_The_New_York_Times.png/1280px-19120417_Some_who_were_saved_when_the_Titanic_went_down_-_The_New_York_Times.png\"\n",
        "URL_TEST = \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Adelaide_tram_number_1_on_trial_run_in_North_Tce_30_Nov_1908.jpg/1280px-Adelaide_tram_number_1_on_trial_run_in_North_Tce_30_Nov_1908.jpg\"\n",
        "URL_TITANIC = \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/RMS_Titanic_3.jpg/1280px-RMS_Titanic_3.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXkucYKYc89J",
        "colab_type": "text"
      },
      "source": [
        "# Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yhYspeJEEO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_feature(\n",
        "    dataframe: pd.DataFrame,\n",
        "    feature: str,\n",
        "    n_parts: int,\n",
        "    qcut=True) -> pd.DataFrame:\n",
        "    \"\"\"Generates label feature\"\"\"\n",
        "    df = dataframe.copy()\n",
        "\n",
        "    feat_sparse = f\"{feature}_label\"\n",
        "    feat_label = f\"{feature}_lbl\"\n",
        "\n",
        "    if qcut:\n",
        "        df[feat_sparse] = pd.qcut(df[feature], n_parts)\n",
        "    else:\n",
        "        df[feat_sparse] = pd.cut(df[feature], n_parts)\n",
        "\n",
        "    df[feat_label] = LabelEncoder().fit_transform(df[feat_sparse])\n",
        "    df.drop(labels=[feat_sparse], axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNYytr22EUhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "media = 0\n",
        "standar_deviation = 0.1\n",
        "nd = np.random.normal(media, standar_deviation, 1000)  # normal distribution\n",
        "\n",
        "df = pd.DataFrame(nd, columns=[\"val\"])  # dataframe of the distribution\n",
        "\n",
        "df = label_feature(\n",
        "    dataframe=df,\n",
        "    feature=\"val\",\n",
        "    n_parts=4,\n",
        "    qcut=False\n",
        ")  # transform val into sparse feature\n",
        "\n",
        "df.hist()\n",
        "plt.show()\n",
        "\n",
        "del media\n",
        "del standar_deviation\n",
        "del nd\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-idHGkWEGoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def red_print(texto: str):\n",
        "    \"\"\"Print text with red color\"\"\"\n",
        "    print(colored(f\"\\n----- {texto} -----\", \"red\"), end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK5ZWk_FHf16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"Roses are red.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcBUOCogEKZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_imputer(\n",
        "    dataframe: pd.DataFrame,\n",
        "    simple=True\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Fills null values\"\"\"\n",
        "    df = dataframe.copy()\n",
        "\n",
        "    cat_df = df[\n",
        "        df.select_dtypes(include=\"object\").columns.tolist() + ['survived']\n",
        "    ]\n",
        "    num_df = df.select_dtypes(exclude=\"object\").drop(labels=\"survived\", axis=1)\n",
        "\n",
        "    if simple:\n",
        "        imputer = IterativeImputer(random_state=42)\n",
        "    else:\n",
        "        imputer = sk.impute.KNNImputer(n_neighbors=7)\n",
        "    imputed = imputer.fit_transform(num_df.values)\n",
        "\n",
        "    num_df = pd.DataFrame(imputed, columns=num_df.columns, dtype=float)\n",
        "\n",
        "    df = pd.merge(cat_df, num_df, left_index=True, right_index=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfm_C8O7ELWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(url: str, x0: int, x1: int):\n",
        "    \"\"\"Show image\"\"\"\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "    plt.imshow(np.asarray(img)[x0: x1, :], cmap='gray', vmin=0, vmax=255)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A69cecqyIB-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(URL_TEST, 200, 800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9d-hiJEENHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_python(url):\n",
        "    response = requests.get(URL_PYTHON)\n",
        "    im = Image.open(BytesIO(response.content))\n",
        "    W, H = im.size\n",
        "\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    draw.rectangle((520, 230, 1100, 250), fill=0)\n",
        "    draw.rectangle((500, 250, 540, 270), fill=0)\n",
        "\n",
        "    draw.rectangle((600, 250, 860, 270), fill=0)\n",
        "    draw.rectangle((630, 250, 650, 270), fill=(255,255,255))\n",
        "    draw.rectangle((620, 270, 860, 290), fill=0)\n",
        "    draw.rectangle((650, 270, 670, 290), fill=(255,255,255))\n",
        "    draw.rectangle((640, 290, 840, 310), fill=0)\n",
        "    draw.rectangle((670, 290, 690, 310), fill=(255,255,255))\n",
        "    draw.rectangle((660, 310, 820, 330), fill=0)\n",
        "\n",
        "    draw.rectangle((900, 250, 1080, 270), fill=0)\n",
        "    draw.rectangle((930, 250, 950, 270), fill=(255,255,255))\n",
        "    draw.rectangle((920, 270, 1080, 290), fill=0)\n",
        "    draw.rectangle((950, 270, 970, 290), fill=(255,255,255))\n",
        "    draw.rectangle((940, 290, 1060, 310), fill=0)\n",
        "    draw.rectangle((970, 290, 990, 310), fill=(255,255,255))\n",
        "    draw.rectangle((960, 310, 1040, 330), fill=0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "    plt.imshow(np.asarray(im)[50: 650, :])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOjrAy19c_UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def titanic_load(url=URL_CSV) -> pd.DataFrame:\n",
        "    \"\"\"Load Titanic dataset\"\"\"\n",
        "    df = pd.read_csv(url)\n",
        "    df.drop(labels=[\"boat\", \"body\", \"home.dest\"], axis=1, inplace=True)\n",
        "    df.rename(\n",
        "        columns={\n",
        "            \"sibsp\": \"siblings_spouses\",\n",
        "            \"parch\": \"parents_children\"\n",
        "        }, inplace=True)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFqQ4ea97rmg",
        "colab_type": "text"
      },
      "source": [
        "# Data description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVRKNutVhWaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(URL_TITANIC, 200, 800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot66pQdP0meF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desc = pd.read_html(URL_HTML)\n",
        "desc = pd.DataFrame(desc[0].values[1:], columns=desc[0].iloc[0])\n",
        "desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVzUIVFC7uQ9",
        "colab_type": "text"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0EsJuByo6EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(URL_PASSENGERS, 200, 800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKUkqcvKSjIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Titaninc dataset\n",
        "df = titanic_load()\n",
        "\n",
        "# This backup copy will be used to show the usefulness of a Transformer\n",
        "backup_1 = df.copy()\n",
        "\n",
        "df.sample(n=10).sort_values(by=['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrNEmCHsUvud",
        "colab_type": "text"
      },
      "source": [
        "# Train Eval Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8QJ7UH0Upp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Titanic dataset will be split in two: train and eval datasets\n",
        "# Train will have 891 registers to reflect Kaggle's challenge\n",
        "\n",
        "train = df.sample(n=891, random_state=0).index\n",
        "eval = df.loc[~df.index.isin(train)].index\n",
        "\n",
        "assert len(set(train.to_list()) & set(eval.to_list())) == 0, \"Split problem\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0QQkF6sb6R6",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZrhjMk2izGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(URL_SURVIVORS, 165, 765)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky0po2qlkWnv",
        "colab_type": "text"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLszGdCSB_eW",
        "colab_type": "text"
      },
      "source": [
        "### Null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_aMyX22YLNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show columns and total missing values\n",
        "dt = df.isna().sum().reset_index().sort_values(by=[0])\n",
        "dt[dt[0] > 0][[\"index\", 0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk4SNCw2BzjV",
        "colab_type": "text"
      },
      "source": [
        "### Null values: fare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzrcOJgwZqak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"fare = null\")\n",
        "print(df[df.fare.isna()][[\"pclass\", \"ticket\", \"fare\"]], end=\"\\n\\n\")\n",
        "\n",
        "# Since fare has only one missing value,\n",
        "# we will use the most common value in the column (mode) for the same pclass.\n",
        "df.loc[df.fare.isna(), \"fare\"] = df[\n",
        "   (df.pclass == 3) & (df.fare.notna())\n",
        "][\"fare\"].mode().values[0]\n",
        "\n",
        "print(df.loc[[1225, 1226], [\"pclass\", \"ticket\", \"fare\"]])\n",
        "\n",
        "red_print(\"pclass x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"pclass\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWcImuLjGvTg",
        "colab_type": "text"
      },
      "source": [
        "### New feature: fare_lbl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeBwSSsmGyoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"fare x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"fare\")\n",
        "plt.show()\n",
        "\n",
        "# Fare is a continuous feature. \n",
        "# Let's make it discrete and split into 4 quantiles.\n",
        "df = label_feature(df, \"fare\", 4)\n",
        "\n",
        "red_print(\"fare_lbl x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"fare_lbl\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeZ6gB0oB2P8",
        "colab_type": "text"
      },
      "source": [
        "### Null values: embarked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgy7vcrTbKoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"embarked = null\")\n",
        "print(df[df.embarked.isna()][[\"ticket\"]], end=\"\\n\\n\")\n",
        "\n",
        "# Since embarked has only two missing values,\n",
        "# let's use the most common values on the dataset.\n",
        "df.loc[df.embarked.isna(), \"embarked\"] = df.embarked.mode().values[0]\n",
        "print(df.loc[[168, 284], [\"ticket\", \"embarked\"]])\n",
        "\n",
        "df[\"embarked_lbl\"] = LabelEncoder().fit_transform(df.embarked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4vzAbA4CLqC",
        "colab_type": "text"
      },
      "source": [
        "### Hidden feature: honorific"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQKneqLOlrl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"name samples\")\n",
        "print(df.name.sample(n=10), end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGXPZAvNltLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This feature will conect age, sex and social status of the passenger.\n",
        "# It is the honorific title used to refer to the passenger.\n",
        "# This feature occurs in the middle of the name.\n",
        "df[\"honorific\"] = df.name.str.split(\",\").apply(\n",
        "    lambda x: x[1]\n",
        ").str.split(\".\").apply(lambda x: x[0]).str.strip()\n",
        "\n",
        "red_print(\"honorific list\")\n",
        "print(df.honorific.unique(), end=\"\\n\\n\")\n",
        "\n",
        "red_print(\"honorific x pclass\")\n",
        "print(df.groupby([\"honorific\", \"pclass\"]).size(), end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsr42pcEMdfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's select honorific titles with less than 10 occurrences and group them.\n",
        "honorific_selection = (df.honorific.value_counts() < 10)\n",
        "honorific_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqEzfHEomcF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The group will be called Rare.\n",
        "df.honorific = df.honorific.apply(\n",
        "    lambda x: \"Rare\" if honorific_selection.loc[x] else x\n",
        ")\n",
        "\n",
        "red_print(\"honorific x pclass\")\n",
        "print(df.groupby([\"honorific\", \"pclass\"]).size(), end=\"\\n\\n\")\n",
        "\n",
        "df[\"honorific_lbl\"] = LabelEncoder().fit_transform(df.honorific)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Q56gTwBQ7Z",
        "colab_type": "text"
      },
      "source": [
        "### New features: family size e alone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24nZLK0UBJ3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Siblings and spouses = horizontal relationships.\n",
        "# Parents and children = vertical relationships.\n",
        "# Family size = horizontal and vertical relationships and self.\n",
        "df['family_size'] = 1 + df['siblings_spouses'] + df['parents_children']\n",
        "\n",
        "# Whether the passenger had no family on the ship.\n",
        "df[\"alone\"] = 1\n",
        "df.loc[df.family_size == 1, \"alone\"] = 0\n",
        "\n",
        "red_print(\"family_size x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"family_size\")\n",
        "plt.show()\n",
        "\n",
        "red_print(\"alone x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"alone\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiZorlxkGK-e",
        "colab_type": "text"
      },
      "source": [
        "### Label encoder: sex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeNDQR0ET6Th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"sex\")\n",
        "print(df.sex.value_counts())\n",
        "\n",
        "# Due to women and children first, most men died.\n",
        "red_print(\"sex (%)\")\n",
        "dt = df.groupby(\n",
        "    [\"sex\"]\n",
        ").size().sort_index().reset_index().rename(columns={0: \"total\"})\n",
        "dt.total = dt.total / df.shape[0] * 1000 // 10\n",
        "print(dt)\n",
        "\n",
        "# Even though they were the majority onboard.\n",
        "red_print(\"sex x survived (%)\")\n",
        "dt = df.loc[train].groupby(\n",
        "    [\"survived\", \"sex\"]\n",
        ").size().sort_index().reset_index().rename(columns={0: \"total\"})\n",
        "dt.total = dt.total / df.loc[train].shape[0] * 1000 // 10\n",
        "print(dt)\n",
        "\n",
        "# We could use Pandas map, but we will use LabelEncoder instead.\n",
        "df[\"sex_lbl\"] = LabelEncoder().fit_transform(df.sex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6hTzFUdCUDX",
        "colab_type": "text"
      },
      "source": [
        "### Null values: age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AG8iWYTnhxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us visualize how age behaves.\n",
        "\n",
        "red_print(\"age w/ null\")\n",
        "df.age.hist()\n",
        "plt.show()\n",
        "\n",
        "red_print(\"age w/ null x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"age\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5hzuK-bTQZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use an IterativeImputer to fill null values\n",
        "# and check if the behavior of the feature doesn't change much.\n",
        "df = simple_imputer(df)\n",
        "\n",
        "red_print(\"age wo/ null\")\n",
        "df.age.hist()\n",
        "plt.show()\n",
        "\n",
        "red_print(\"age wo/ null x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"age\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUT33Y5dDxfJ",
        "colab_type": "text"
      },
      "source": [
        "### New feature: age_lbl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2GhmvxDx58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red_print(\"age x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"age\")\n",
        "plt.show()\n",
        "\n",
        "# age is also a feature with too many different values.\n",
        "# Let's group these values by stages of life using Pandas cut.\n",
        "df = label_feature(df, \"age\", 5, False)\n",
        "\n",
        "red_print(\"age_lbl x survived\")\n",
        "sns.FacetGrid(df.loc[train], col=\"survived\").map(sns.distplot, \"age_lbl\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb-SZ1F-Cdqh",
        "colab_type": "text"
      },
      "source": [
        "### Hidden feature: deck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9t7PG9rkGwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(URL_DECKS, 0, 350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEpcRW1HiTMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deck is a feature that can be obtained within the cabin feature.\n",
        "# The problem is the majority of values is null.\n",
        "# So we won't use this feature afterwards.\n",
        "df['deck'] = df.cabin.apply(lambda x: x[0] if type(x) == str else \"M\")\n",
        "\n",
        "red_print(\"deck\")\n",
        "print(df.deck.value_counts(dropna=False))\n",
        "\n",
        "red_print(\"Cabin T was close to A\")\n",
        "df.loc[df.deck == \"T\", \"deck\"] = \"A\"\n",
        "\n",
        "red_print(\"deck\")\n",
        "print(df.deck.value_counts(dropna=False))\n",
        "\n",
        "# As an exercise of practice, let's label encode the deck feature.\n",
        "df[\"deck_lbl\"] = LabelEncoder().fit_transform(df.deck)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w0cBrnor9UH",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct-oW5_vhmev",
        "colab_type": "text"
      },
      "source": [
        "### Data sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSLig-HR1-9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enough engineering, let's visualize how is our dataset.\n",
        "df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMqxa1OAhxCb",
        "colab_type": "text"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS4OSfo7B4VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since we have encoded most of our features into discrete values,\n",
        "# let's select all numerical features and exclude continuous features.\n",
        "# Let's also exclude features encoded in newer features like\n",
        "# siblings_spouses, parents_children and alone.\n",
        "numerical = df.select_dtypes(exclude=\"object\").columns.tolist()\n",
        "numerical.remove(\"age\")\n",
        "numerical.remove(\"fare\")\n",
        "numerical.remove(\"deck_lbl\")\n",
        "numerical.remove(\"siblings_spouses\")\n",
        "numerical.remove(\"parents_children\")\n",
        "numerical.remove(\"alone\")\n",
        "\n",
        "# The result is this list of features.\n",
        "red_print(\"Numerical features\")\n",
        "print(numerical)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_12jkRgBnYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's exercize our coding checking categorical features\n",
        "# for those with more than 10 unique values.\n",
        "# These are the ones that should be discarded for representing\n",
        "# too much variation.\n",
        "categorical = []\n",
        "for column in df.select_dtypes(include=\"object\").columns:\n",
        "    if df[column].value_counts().shape[0] <= 10:\n",
        "        categorical.append(column)\n",
        "    else:\n",
        "        print(\"Removed feature:\", column)\n",
        "\n",
        "red_print(\"Categorical features\")\n",
        "print(categorical)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRRsbzlE-UOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Time to assert if all the features are filled with values.\n",
        "assert sum(df[numerical].isna().sum().values) == 0, \"Null value detected\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X02Wvv2IhiIb",
        "colab_type": "text"
      },
      "source": [
        "## Graphical analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaPmtPINDxf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to proceed into a graphical analysis, let's consider\n",
        "# only training data. Otherwise we would be looking into the future.\n",
        "sel = df.loc[train, numerical]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvgUhdE1eAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A heatmap allows us to look for features with high correlation.\n",
        "# Luckily there is none.\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "g = sns.heatmap(sel.corr(), annot=True, cmap='coolwarm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcBcAvz9zlQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pandas corr allows us to do the same without the colors. Lame.\n",
        "sel.corr(method='pearson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-A6Mt5hz1Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pandas skew is used to analyse the inclination of the normal curve.\n",
        "sel.skew()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB-eeqAv0HmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pandas hist let us analyse global behavior of features.\n",
        "sel.hist(figsize=(15, 15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPoWiUi7Wil4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Boxplot is a useful graph to detect outliers.\n",
        "# The box is the interval interquartile.\n",
        "# The whiskers the rest of the distribution.\n",
        "# The dots are the outliers.\n",
        "# Not very useful here though.\n",
        "for column in df.select_dtypes(exclude=\"object\").columns:\n",
        "    if column == \"survived\" or \"_\" in column:\n",
        "        continue\n",
        "    plt.boxplot(df.loc[train, column], showmeans=True, meanline=True)\n",
        "    plt.ylabel(column)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfwINjqpJJIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This time we will plot some histogram comparing how two features\n",
        "# relate to the survived feature.\n",
        "hist = sns.FacetGrid(df.loc[train], row='sex', col='pclass', hue='survived')\n",
        "hist.map(plt.hist, 'age', alpha = .75)\n",
        "hist.add_legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3_Ll0rkKOuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also compare how each feature relate to the survived feature.\n",
        "# This helps us see if these features make sense to solve the problem at hand.\n",
        "label = \"survived\"\n",
        "columns = [x for x in sel.columns if x != label]\n",
        "\n",
        "for column in columns:\n",
        "    print(f\"Survival rate by {column}\")\n",
        "    print(\n",
        "        sel[[column, label]].groupby([column], as_index=False) \\\n",
        "        .sum().sort_values(by=[\"survived\"], ascending=False),\n",
        "        end=\"\\n\\n\"\n",
        "    )\n",
        "    sns.FacetGrid(df, col=label).map(sns.distplot, column)\n",
        "    plt.show()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rchJooZLapCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Barplots are used to correlate two features with survived feature.\n",
        "# The lower the wick, the greater the certain.\n",
        "\n",
        "# \"A bar plot represents an estimate of central tendency for a numeric \n",
        "# variable with the height of each rectangle and provides some indication \n",
        "# of the uncertainty around that estimate using error bars.\"\n",
        "# (https://seaborn.pydata.org/generated/seaborn.barplot.html)\n",
        "\n",
        "fig, qaxis = plt.subplots(3, 1, figsize=(15, 15))\n",
        "\n",
        "sns.barplot(x='sex_lbl', y='survived', hue='pclass', data=sel, ax=qaxis[0])\n",
        "qaxis[0].set_title('sex_lbl x pclass x survived')\n",
        "\n",
        "sns.barplot(x='fare_lbl', y='survived', hue='honorific_lbl', data=sel, ax=qaxis[1])\n",
        "qaxis[1].set_title('fare_lbl x honorific_lbl x survived')\n",
        "\n",
        "sns.barplot(x='embarked_lbl', y='survived', hue='age_lbl', data=sel, ax=qaxis[2])\n",
        "qaxis[2].set_title('family_size x age_lbl x survived')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pJrH0eed9hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's check on how our data looks like.\n",
        "sel.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQJuQb_8sk6J",
        "colab_type": "text"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhL-Br0xmYbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that you are certain about your data engineering, put\n",
        "# everything in a Transformer to allow the use of pipelines\n",
        "# and to guarantee that all data will be prepared in the\n",
        "# same way.\n",
        "\n",
        "class TitanicTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key=None):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "\n",
        "        # FARE\n",
        "        df.loc[df.fare.isna(), \"fare\"] = df[(df.pclass == 3) & (df.fare.notna())][\"fare\"].mode().values[0]\n",
        "        df = label_feature(df, \"fare\", 4)\n",
        "\n",
        "        # EMBARKED\n",
        "        df.loc[df.embarked.isna(), \"embarked\"] = df.embarked.mode().values[0]\n",
        "        df[\"embarked_lbl\"] = LabelEncoder().fit_transform(df.embarked)\n",
        "\n",
        "        # HONORIFIC\n",
        "        df[\"honorific\"] = df.name.str.split(\",\").apply(lambda x: x[1]).str.split(\".\").apply(lambda x: x[0]).str.strip()\n",
        "        honorific_selection = (df.honorific.value_counts() < 10)\n",
        "        df.honorific = df.honorific.apply(lambda x: \"Rare\" if honorific_selection.loc[x] else x)\n",
        "        df[\"honorific_lbl\"] = LabelEncoder().fit_transform(df.honorific)\n",
        "\n",
        "        # FAMILY\n",
        "        df['family_size'] = 1 + df['siblings_spouses'] + df['parents_children']\n",
        "        df[\"alone\"] = 1\n",
        "        df.loc[df.family_size == 1, \"alone\"] = 0\n",
        "\n",
        "        # SEX\n",
        "        df[\"sex_lbl\"] = LabelEncoder().fit_transform(df.sex)\n",
        "\n",
        "        # AGE\n",
        "        df = simple_imputer(df)\n",
        "        df = label_feature(df, \"age\", 5, False)\n",
        "\n",
        "        # SELECT NUMERICAL FEATURES\n",
        "        numerical = df.select_dtypes(exclude=\"object\").columns.tolist()\n",
        "        numerical.remove(\"age\")\n",
        "        numerical.remove(\"fare\")\n",
        "        numerical.remove(\"siblings_spouses\")\n",
        "        numerical.remove(\"parents_children\")\n",
        "        numerical.remove(\"alone\")\n",
        "\n",
        "        return df[numerical]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfQkRiEosvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will apply the transformation on the original data.\n",
        "sel = TitanicTransformer().fit_transform(backup_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoicL-10pFeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sel.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl06Sl5wppnF",
        "colab_type": "text"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxx8op4Np3aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First things first. Let's load the iceberg. Without it there's no accident.\n",
        "show_img(URL_ICEBERG, 0, 600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCziFJiUsO0f",
        "colab_type": "text"
      },
      "source": [
        "## **Without** data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5c0iQNtltIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(URL_DISASTER, 0, 600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkWnZP1u-YIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to check if our preprocessing makes any difference we will run a\n",
        "# model on the original data with very basic preprocessing like filling\n",
        "# missing data and label encoding categorical features.\n",
        "sel = backup_1.copy()\n",
        "\n",
        "# Drop features with too much unique values\n",
        "sel.drop(labels=[\"name\", \"ticket\", \"cabin\"], axis=1, inplace=True)\n",
        "\n",
        "# Fill null values\n",
        "sel.age.fillna(0, inplace=True)\n",
        "sel.embarked.fillna(\"\", inplace=True)\n",
        "sel.fare.fillna(\"\", inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "for column in sel.select_dtypes(include=\"object\").columns.to_list():\n",
        "    sel[column] = LabelEncoder().fit_transform(sel[column].astype(str))\n",
        "\n",
        "# Train eval split\n",
        "train_df = sel.loc[train]\n",
        "eval_df = sel.loc[eval]\n",
        "\n",
        "# Split dataset into labels and features\n",
        "y = train_df.survived\n",
        "X = train_df.drop(labels=\"survived\", axis=1)\n",
        "y_eval = eval_df.survived\n",
        "X_eval = eval_df.drop(labels=\"survived\", axis=1)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=0.7, random_state=42\n",
        ")\n",
        "\n",
        "# Instantiate classifier\n",
        "clf = SVC()\n",
        "\n",
        "# Model training\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(\"Training score\", score)\n",
        "\n",
        "# Final training and evaluation\n",
        "clf.fit(X, y)\n",
        "score = clf.score(X_eval, y_eval)\n",
        "print(\"   Final score\", score)\n",
        "\n",
        "# The result can be seen in the following confusion matrix.\n",
        "# The confusion matrix shows true negatives, true positives, false negatives \n",
        "# and false positives.\n",
        "plot_confusion_matrix(clf, X_eval, y_eval, values_format=\"d\")\n",
        "plt.show()\n",
        "\n",
        "# Basically, the model decided to kill everyone onboard. Bad model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeSzF7z0AE7M",
        "colab_type": "text"
      },
      "source": [
        "## **With** data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyK5vwdqh5d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SPOILER ALERT!\n",
        "show_img(URL_LIFEBOAT, 150, 750)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngm7gf_AcS5d",
        "colab_type": "text"
      },
      "source": [
        "### Label encoded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EudgIOpFZLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This first model will use our transformer with label encoded data.\n",
        "sel = TitanicTransformer().fit_transform(backup_1)\n",
        "\n",
        "# Train eval split\n",
        "train_df = sel.loc[train]\n",
        "eval_df = sel.loc[eval]\n",
        "\n",
        "# Split dataset into labels and features\n",
        "y = train_df.survived\n",
        "X = train_df.drop(labels=\"survived\", axis=1)\n",
        "y_eval = eval_df.survived\n",
        "X_eval = eval_df.drop(labels=\"survived\", axis=1)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=0.7, random_state=42\n",
        ")\n",
        "\n",
        "# Instantiate classifier\n",
        "clf = SVC()\n",
        "\n",
        "# Model training\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(\"Training score\", score)\n",
        "\n",
        "# Predict\n",
        "y_pred_1 = clf.predict(X_eval)\n",
        "\n",
        "# Final training and evaluation\n",
        "clf.fit(X, y)\n",
        "score = clf.score(X_eval, y_eval)\n",
        "print(\"   Final score\", score)\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, X_eval, y_eval, values_format=\"d\")\n",
        "plt.show()\n",
        "\n",
        "# 80%! Not bad. The model decided to abandon his evil deeds."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBcE7ssUcYbC",
        "colab_type": "text"
      },
      "source": [
        "### One hot encoded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhijhhmU3J9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This time we will use the transformer and one hot encoder \n",
        "# to see the difference.\n",
        "sel = TitanicTransformer().fit_transform(backup_1)\n",
        "\n",
        "# Train eval split\n",
        "train_df = sel.loc[train]\n",
        "eval_df = sel.loc[eval]\n",
        "\n",
        "# Split dataset into labels and features\n",
        "y = train_df.survived\n",
        "X = train_df.drop(labels=\"survived\", axis=1)\n",
        "y_eval = eval_df.survived\n",
        "X_eval = eval_df.drop(labels=\"survived\", axis=1)\n",
        "\n",
        "for column in X.columns:\n",
        "    X[column] = X[column].apply(lambda x: f\"{column}_{x}\")\n",
        "    X_eval[column] = X_eval[column].apply(lambda x: f\"{column}_{x}\")\n",
        "\n",
        "encoder = sk.preprocessing.OneHotEncoder(drop=\"first\")\n",
        "X_oh = encoder.fit_transform(X)\n",
        "X_eval_oh = encoder.transform(X_eval)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_oh, y, train_size=0.7, random_state=42\n",
        ")\n",
        "\n",
        "# Instantiate classifier\n",
        "clf = SVC()\n",
        "\n",
        "# Model training\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(\"Training score\", score)\n",
        "\n",
        "# Predict\n",
        "y_pred_2 = clf.predict(X_eval_oh)\n",
        "\n",
        "# Final training and evaluation\n",
        "clf.fit(X_oh, y)\n",
        "score = clf.score(X_eval_oh, y_eval)\n",
        "print(\"   Final score\", score)\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, X_eval_oh, y_eval, values_format=\"d\")\n",
        "plt.show()\n",
        "\n",
        "# The result is very similar to the one with only label encoding."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3PwYx0Ycmc5",
        "colab_type": "text"
      },
      "source": [
        "### Difference between results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzMvM58eQie2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The confusion matrix can also be used to check if both models\n",
        "# got the same rights and wrongs.\n",
        "\n",
        "cm = confusion_matrix(y_pred_1, y_pred_2)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=[\"DIED\", \"SURVIVED\"])\n",
        "cmd.plot(values_format=\"d\")\n",
        "plt.show()\n",
        "\n",
        "# As we can see, there are some disturbances on the force. We could use this\n",
        "# to our advantage, trying many models and choosing the most common results.\n",
        "# But that's for another summit."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-7H0HUsMYhc",
        "colab_type": "text"
      },
      "source": [
        "# What now?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsrTLwXEMaTe",
        "colab_type": "text"
      },
      "source": [
        "#### Cross validation\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "#### Hyper-parameters tuning\n",
        "https://scikit-learn.org/stable/modules/grid_search.html\n",
        "\n",
        "#### Feature selection\n",
        "https://scikit-learn.org/stable/modules/feature_selection.html\n",
        "\n",
        "#### Feature augmentation\n",
        "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
        "\n",
        "#### Ensemble\n",
        "https://scikit-learn.org/stable/modules/ensemble.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_n3Ovj0M89",
        "colab_type": "text"
      },
      "source": [
        "# Any doubts? Questions?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNR4kvijrcxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_python(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM3OA2P7a51",
        "colab_type": "text"
      },
      "source": [
        "# My social media"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjWhFs-B8KpU",
        "colab_type": "text"
      },
      "source": [
        "**Cláudio Gomes**\n",
        "\n",
        "https://www.linkedin.com/in/claudiohfg/\n",
        "\n",
        "https://www.kaggle.com/claudiohfg\n",
        "\n",
        "https://www.facebook.com/claudiohfg\n",
        "\n",
        "https://twitter.com/claudiohfg\n",
        "\n",
        "https://www.instagram.com/claudiohfg.art/\n",
        "\n",
        "https://www.instagram.com/claudiohfg/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIl3zfY2ZmSa",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYYyCjygDam",
        "colab_type": "text"
      },
      "source": [
        "Datasets\n",
        "http://biostat.mc.vanderbilt.edu/wiki/Main/DataSets\n",
        "\n",
        "Encyclopedia Titanica\n",
        "https://www.encyclopedia-titanica.org/\n",
        "\n",
        "Wikipedia RMS Titanic\n",
        "https://en.wikipedia.org/wiki/RMS_Titanic\n",
        "\n",
        "Wikipedia English Honorifics\n",
        "https://en.wikipedia.org/wiki/English_honorifics\n",
        "\n",
        "Pandas cut\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html\n",
        "\n",
        "Pandas qcut\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html\n",
        "\n",
        "Scitkit-Learn User Guide\n",
        "https://scikit-learn.org/stable/user_guide.html\n",
        "\n",
        "Scikit-Learn Cheat Sheet\n",
        "https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf\n",
        "\n",
        "Matplotlib Tutorials\n",
        "https://matplotlib.org/tutorials/index.html\n",
        "\n",
        "Seaborn Tutorials\n",
        "https://seaborn.pydata.org/tutorial.html\n",
        "\n",
        "ClaudioHFG's Kaggle notebook\n",
        "https://www.kaggle.com/claudiohfg/titanic-ensemble-with-sklearn-0-81339\n",
        "\n",
        "LD Freeman's Kaggle notebook\n",
        "https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy"
      ]
    }
  ]
}